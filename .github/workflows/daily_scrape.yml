name: Daily RAM Scraper

on:
  schedule:
    - cron: '0 6 * * *'   # todos los días 06:00 UTC
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt

      - name: Run scraper
        run: |
          python backend/app/scrapers/run_scraper.py
      - name: Debug – buscar latest.json
        run: |
            echo "Mostrando estructura:"
            ls
            echo "Buscando latest.json en todo el repo:"
            find . -name "latest.json"


      - name: Upload to Cloudflare (optional)
        env:
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_KV_NAMESPACE: ${{ secrets.CF_KV_NAMESPACE }}
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        run: |
          echo "Si los secrets existen, aca iría el upload a Cloudflare"

      - name: Publish data to GitHub Pages
        run: |
          mkdir -p docs/data
          cp output/latest.json docs/data/latest.json

          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add docs/data/latest.json
          git commit -m "Update data" || echo "No changes"
          git push
